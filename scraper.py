import requests
import json
import datetime
import re
from bs4 import BeautifulSoup

# === Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…ØµØ§Ø¯Ø± ===
# Ø±Ø§Ø¨Ø· Ù…Ù„Ù Ø§Ù„Ù‚Ù†ÙˆØ§Øª (Ø§Ù„Ø°ÙŠ Ù†Ø£Ø®Ø° Ù…Ù†Ù‡ Ø§Ù„Ø¨Ø«)
IPTV_URL = "https://gist.githubusercontent.com/yasiralbeatiy/a078d245888ce7eb892e04d120f1420c/raw/a6b268326c30276367a62947e4dc862b1b171410/beinsport.m3u"

def get_iptv_links():
    """Ø¬Ù„Ø¨ Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù‚Ù†ÙˆØ§Øª ÙˆØªÙ†Ø¸ÙŠÙ Ø£Ø³Ù…Ø§Ø¦Ù‡Ø§"""
    print("Ø¬Ø§Ø±ÙŠ Ø¬Ù„Ø¨ Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ø¨Ø«...")
    channels = {}
    try:
        response = requests.get(IPTV_URL)
        lines = response.text.splitlines()
        for i, line in enumerate(lines):
            if "#EXTINF" in line and "http" in lines[i+1]:
                # Ù…Ø­Ø§ÙˆÙ„Ø© ØªÙ†Ø¸ÙŠÙ Ø§Ø³Ù… Ø§Ù„Ù‚Ù†Ø§Ø© Ù„ÙŠØ³Ù‡Ù„ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù†Ù‡
                raw_name = line.split(",")[-1].strip().lower()
                # Ø­Ø°Ù Ø§Ù„Ø±Ù…ÙˆØ² ÙˆØªØ±Ùƒ Ø§Ù„Ø§Ø±Ù‚Ø§Ù… ÙˆØ§Ù„Ø­Ø±ÙˆÙ ÙÙ‚Ø· (bein sports 1 -> beinsports1)
                clean_name = re.sub(r'[^a-z0-9]', '', raw_name)
                url = lines[i+1].strip()
                channels[clean_name] = url
    except Exception as e:
        print(f"Error fetching IPTV: {e}")
    return channels

def get_today_matches():
    """Ø¬Ù„Ø¨ Ù…Ø¨Ø§Ø±ÙŠØ§Øª Ø§Ù„ÙŠÙˆÙ… Ù…Ù† Ù…ØµØ¯Ø± Ø¹Ø±Ø¨ÙŠ Ù…ÙˆØ«ÙˆÙ‚ (ÙŠÙ„Ø§ ÙƒÙˆØ±Ø© ÙƒÙ…Ø«Ø§Ù„ Ù„Ù„Ø¯Ù‚Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©)"""
    print("Ø¬Ø§Ø±ÙŠ Ø¬Ù„Ø¨ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ø¨Ø§Ø±ÙŠØ§Øª...")
    matches = []
    try:
        # Ù†Ø³ØªØ®Ø¯Ù… ÙŠÙ„Ø§ ÙƒÙˆØ±Ø© Ù„Ø£Ù†Ù‡ ÙŠÙˆÙØ± Ø§Ø³Ù… Ø§Ù„Ù‚Ù†Ø§Ø© Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠ ÙˆÙ‡Ø°Ø§ ÙŠØ³Ù‡Ù„ Ø§Ù„Ø±Ø¨Ø·
        headers = {"User-Agent": "Mozilla/5.0"}
        res = requests.get("https://www.yallakora.com/match-center/", headers=headers)
        soup = BeautifulSoup(res.content, 'html.parser')
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙƒÙ„ Ø§Ù„Ù…Ø¨Ø§Ø±ÙŠØ§Øª ÙÙŠ Ø§Ù„ØµÙØ­Ø©
        all_matches = soup.find_all('div', class_='item')
        
        for item in all_matches:
            try:
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                team_a = item.find('div', class_='teamA').find('p').text.strip()
                logo_a = item.find('div', class_='teamA').find('img')['src']
                
                team_b = item.find('div', class_='teamB').find('p').text.strip()
                logo_b = item.find('div', class_='teamB').find('img')['src']
                
                match_time = item.find('span', class_='time').text.strip()
                
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù‚Ù†Ø§Ø© Ø§Ù„Ù†Ø§Ù‚Ù„Ø©
                channel_div = item.find('div', class_='channel')
                channel_name = channel_div.text.strip() if channel_div else "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ"
                
                # Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø¨Ø§Ø±Ø§Ø© (Ø¬Ø§Ø±ÙŠØ©ØŒ Ø§Ù†ØªÙ‡ØªØŒ Ù„Ù… ØªØ¨Ø¯Ø£)
                status = "upcoming"
                if "now" in item.get('class', []): status = "live"
                if "finish" in item.get('class', []): status = "finished"

                matches.append({
                    "team_a": team_a, "logo_a": logo_a,
                    "team_b": team_b, "logo_b": logo_b,
                    "time": match_time,
                    "channel": channel_name,
                    "status": status
                })
            except:
                continue
    except Exception as e:
        print(f"Error fetching matches: {e}")
    return matches

def main():
    iptv_data = get_iptv_links()
    matches_data = get_today_matches()
    
    final_list = []
    
    print("Ø¬Ø§Ø±ÙŠ Ø±Ø¨Ø· Ø§Ù„Ù…Ø¨Ø§Ø±ÙŠØ§Øª Ø¨Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ø¨Ø«...")
    for match in matches_data:
        stream_link = ""
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø°ÙƒÙŠØ© Ù„Ù„Ø±Ø¨Ø·: Ù‡Ù„ Ø§Ø³Ù… Ø§Ù„Ù‚Ù†Ø§Ø© Ø§Ù„Ù†Ø§Ù‚Ù„Ø© Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ù…Ù„Ù Ø§Ù„Ø±ÙˆØ§Ø¨Ø·ØŸ
        # ØªØ­ÙˆÙŠÙ„ "beIN Sports 1" Ø¥Ù„Ù‰ "beinsports1"
        target_channel = re.sub(r'[^a-z0-9]', '', match['channel'].lower().replace("hd", ""))
        
        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø±ÙˆØ§Ø¨Ø·
        for ch_key, ch_url in iptv_data.items():
            if target_channel in ch_key or ch_key in target_channel:
                stream_link = ch_url
                break
        
        # Ø§Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø¨Ø§Ø±Ø§Ø© Ù„Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        final_list.append({
            **match,
            "stream_url": stream_link
        })
        
    # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
    output = {
        "updated_at": str(datetime.datetime.now()),
        "matches": final_list
    }
    
    with open("channels.json", "w", encoding="utf-8") as f:
        json.dump(output, f, ensure_ascii=False, indent=2)
    print("ØªÙ… Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø¨Ù†Ø¬Ø§Ø­! ğŸ‰")

if __name__ == "__main__":
    main()
